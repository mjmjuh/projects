ENSEMBLE STACKING luokittelumalli

Saavuttaa noin 70% tarkkuuden
Aineisto: winequality-red
Target-muuttuja "quality"

# KIRJASTOT
import pandas as pd
import numpy as np
import sklearn
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, ExtraTreesClassifier
from sklearn.utils import shuffle
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from vecstack import stacking
from sklearn.metrics import mean_absolute_error, mean_squared_error
import matplotlib.pyplot as plt

# DATAFRAME JA MUOKKAUS
data = pd.read_csv("C:/Users/Markus/Documents/winequality-red.csv", sep = ',')
# poistetaan rivit, joilla tyhjiä
data.dropna(axis = 0, how = 'any', thresh = None, subset = None, inplace = True)

y = data['quality']
X = data.loc[:, data.columns != 'quality']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = 0, shuffle = True)

# ENSEMBLE STACKING
testing = GradientBoostingClassifier(learning_rate=0.1, max_depth = 10, warm_start = True)

max_acc_score1 = float(0)
score_going_down = 0
for n in range(1,1000):
    testing.n_estimators = n
    testing.fit(X_train, y_train)
    y_pred = testing.predict(X_test)
    acc_score = accuracy_score(y_test, y_pred)
    plt.plot(n, acc_score, 'ro')
    if acc_score > max_acc_score1:
        max_acc_score1 = acc_score
        best_est = n
        score_going_down = 0
    else:
        score_going_down += 1
        if score_going_down == 500:
            best_est
            max_acc_score1
            break #early stopping
            
print("Paras n_estimators määrä ja tarkkuus")
print(best_est)
print(max_acc_score1)
plt.show()

randomforest = RandomForestClassifier()
extratrees = ExtraTreesClassifier()
gradientboosting = GradientBoostingClassifier(n_estimators=best_est, learning_rate=0.1, max_depth = 10, warm_start = True)

models = [gradientboosting, randomforest, extratrees]
S_train, S_test = stacking(models,
                           X_train, y_train, X_test,
                           regression = False,
                           n_folds=4,
                           stratified=True,
                           shuffle=False,
                           random_state=0, 
                           verbose = 2)
                           
testing = GradientBoostingClassifier(learning_rate=0.1, max_depth = 10, warm_start = True)


max_acc_score = float(0)
score_going_down = 0
for n in range(1,1000):
    testing.n_estimators = n
    testing.fit(S_train, y_train)
    y_pred = testing.predict(S_test)
    acc_score = accuracy_score(y_test, y_pred)
    plt.plot(n, acc_score, 'ro')
    if acc_score > max_acc_score:
        max_acc_score = acc_score
        best_est = n
        score_going_down = 0
    else:
        score_going_down += 1
        if score_going_down == 500:
            best_est
            max_acc_score
            break #early stopping


model = GradientBoostingClassifier(n_estimators=best_est, learning_rate=0.1, max_depth = 10, warm_start = True)

model.fit(S_train, y_train)
print("paras n_estimators määrä")
print(best_est)
plt.show()
            

mse1 = mean_absolute_error(y_train, model.predict(S_train))
mse2 = mean_absolute_error(y_test, model.predict(S_test))

print("traini squared: %.2f" %model.score(S_train, y_train))
print("testi squared: %.2f" %model.score(S_test, y_test))

print(max_acc_score1)
print("Lopullinen saavutettu tarkkuus")
print(accuracy_score(y_test, model.predict(S_test)))
